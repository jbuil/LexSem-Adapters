{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!lscpu"
      ],
      "metadata": {
        "id": "vKDYYz7psywc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "0HMg2DUxa5pq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDhnOvYDMZiu"
      },
      "source": [
        "# **Preparation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DnT5DPRWLyL8"
      },
      "outputs": [],
      "source": [
        "!pip install adapter-transformers transformers datasets evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VA-cxzX8Mnwy"
      },
      "outputs": [],
      "source": [
        "!gdown 'https://drive.google.com/uc?id=1KWokWHSR9i5QYzaY1PGmB7qAzsj2SuOk'\n",
        "!unzip lexical_datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Script**"
      ],
      "metadata": {
        "id": "H6GWWQxGZrhd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python lrc_train_evaluate_adapters.py \\\n",
        "\t--train_templates \"' <W1> ' <SEP> ' <W2> '\" \\\n",
        "\t--model  \"roberta-base\" \\\n",
        "  --use_adapters True \\\n",
        "\t--nepochs 10 \\\n",
        "\t--dir_output_results \"results/\" \\\n",
        "\t--batch_size 32 \\\n",
        "\t--nrepetitions 1 \\\n",
        "\t--dataset \"EVALution\" \\\n",
        "\t--date `date \"+%D-%H:%M:%S\"` \\\n",
        "\t--train_file \"lexical_datasets/EVALution/train.tsv\" \\\n",
        "\t--test_file \"lexical_datasets/EVALution/test.tsv\" \\\n",
        "\t--val_file \"lexical_datasets/EVALution/val.tsv\""
      ],
      "metadata": {
        "id": "60YsNAxDZvaX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArFuqFUlMr1N"
      },
      "source": [
        "# **Loading the tokenizer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_BYqpRYMnyi"
      },
      "outputs": [],
      "source": [
        "from transformers import RobertaTokenizer, RobertaForSequenceClassification, RobertaConfig, RobertaModelWithHeads, AdapterConfig, TrainingArguments, Trainer, AdapterTrainer\n",
        "from sklearn.metrics import classification_report\n",
        "from google.colab import files\n",
        "from collections import Counter\n",
        "\n",
        "model_name = 'roberta-base'\n",
        "tokenizer = RobertaTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YynnREkNCg3"
      },
      "source": [
        "# **Preparing the data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KtysYuaPOJWO"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "# templates to verbalize the words in a relation\n",
        "template1 = \"' <W1> ' <SEP> ' <W2> '\"\n",
        "template2 = \" <W1> <SEP> <W2> \"\n",
        "\n",
        "# function to verbalize the words in a relation\n",
        "def verbalize_words(row, template, tokenizer):\n",
        "    w1 = str(row['source'])\n",
        "    w2 = str(row['target'])\n",
        "    sentence = re.sub(\"<W1>\", w1, template)\n",
        "    sentence = re.sub(\"<W2>\", w2, sentence)\n",
        "    sentence = re.sub(\"<SEP>\", tokenizer.sep_token, sentence)\n",
        "    return {'verb':sentence}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xAeNDmweOYgJ"
      },
      "outputs": [],
      "source": [
        "def preprocess_function(rows, tokenizer):\n",
        "    \"\"\" tokenize the column 'verb' of the rows\"\"\"\n",
        "    inputs = tokenizer(rows['verb'], padding='max_length', max_length=64, return_tensors=\"pt\")\n",
        "    return inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iOKHKUYvNS26"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "def load_data(data_files):\n",
        "    # load the train/val/test datasets\n",
        "    all_datasets = load_dataset('csv',\n",
        "                            data_files=data_files,\n",
        "                            sep = '\\t',\n",
        "                            header=None,\n",
        "                            names=['source', 'target', 'rel'],\n",
        "                            keep_default_na=False)\n",
        "\n",
        "    # create the column 'labels', copy of column 'rel'\n",
        "    all_datasets = all_datasets.map(lambda x: {'labels':x['rel']})\n",
        "\n",
        "    # trasform column 'labels' to a integer with a label id. Needed to fine-tune the model\n",
        "    all_datasets = all_datasets.class_encode_column('labels')\n",
        "\n",
        "    # add a column to the train/val/test datasets with the verbalization\n",
        "    all_datasets = all_datasets.map(verbalize_words, fn_kwargs={'template':template1, 'tokenizer':tokenizer})\n",
        "\n",
        "    # prepare datasets for the LM. We need input_ids, attention_mask and labels (the correct ones)\n",
        "    encoded_datasets = all_datasets.map(preprocess_function, batched=True, batch_size=None,fn_kwargs={'tokenizer':tokenizer})\n",
        "\n",
        "    # remove all columns except those needed to train/evalauate the model\n",
        "    # this step is not necessary. We can leave the columns.\n",
        "    encoded_datasets = encoded_datasets.remove_columns(['source', 'target', 'rel', 'verb'])\n",
        "\n",
        "    return all_datasets, encoded_datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HtzkOiBINBGm"
      },
      "outputs": [],
      "source": [
        "import evaluate\n",
        "import numpy as np\n",
        "\n",
        "# we will get the best model based on the macro f1 score over the val dataset\n",
        "# download the metric from huggingface using the evaluate package\n",
        "metric_name = \"f1\"\n",
        "metric = evaluate.load(metric_name)\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    '''\n",
        "    Compute metrics for a Trainer.\n",
        "\n",
        "    Args:\n",
        "     eval_pred: object of type transformers.EvalPrediction. It is a tuple with\n",
        "     predictions (logits) and real labels.\n",
        "\n",
        "    Returns:\n",
        "     A dictionary of metrics {'name_metric1':value1,...}\n",
        "    '''\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis = 1)\n",
        "    return metric.compute(predictions=predictions, references=labels, average='macro')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yOZXUAUWmX6Y"
      },
      "outputs": [],
      "source": [
        "def save_adapter(model, adapter_name):\n",
        "    model.save_adapter(adapter_name, adapter_name)\n",
        "    !zip -r {adapter_name}.zip {adapter_name}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TOBvO52AU51_"
      },
      "outputs": [],
      "source": [
        "def results_to_file(dataset, real_rels, pred_rels, file):\n",
        "  with open(file, 'w') as f:\n",
        "        f.write(f'Training Time: minutes\\n\\n')\n",
        "        f.write(str(report_dict))\n",
        "        f.write('\\n\\n')\n",
        "        for i, row in enumerate(dataset):\n",
        "          source = row[\"source\"]\n",
        "          target = row[\"target\"]\n",
        "          rel = row[\"rel\"]\n",
        "          if rel != real_rels[i]:\n",
        "            raise ValueError\n",
        "          pred = pred_rels[i]\n",
        "          f.write(f\"{source} {target} {rel} {pred}\\n\")\n",
        "  files.download(file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVzCE-UyO3an"
      },
      "source": [
        "# **Adapters & Fine-Tuning training with EVALution**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RuPl0N6VO-Ss"
      },
      "outputs": [],
      "source": [
        "all_datasets_EVALution, encoded_datasets_EVALution = load_data({'train':'lexical_datasets/EVALution/train.tsv', 'val':'lexical_datasets/EVALution/val.tsv', 'test':'lexical_datasets/EVALution/test.tsv'})\n",
        "print(all_datasets_EVALution)\n",
        "print(encoded_datasets_EVALution)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_bQ6bgbJlZib"
      },
      "outputs": [],
      "source": [
        "etiquetas_train = all_datasets_EVALution[\"train\"][\"rel\"]\n",
        "etiquetas_test = all_datasets_EVALution[\"test\"][\"rel\"]\n",
        "etiquetas_val = all_datasets_EVALution[\"val\"][\"rel\"]\n",
        "\n",
        "conteo_etiquetas_train = Counter(etiquetas_train)\n",
        "conteo_etiquetas_test = Counter(etiquetas_test)\n",
        "conteo_etiquetas_val = Counter(etiquetas_val)\n",
        "\n",
        "etiquetas = set(etiquetas_train)\n",
        "\n",
        "for etiqueta in etiquetas:\n",
        "    conteo_train = conteo_etiquetas_train.get(etiqueta, 0)\n",
        "    conteo_test = conteo_etiquetas_test.get(etiqueta, 0)\n",
        "    conteo_val = conteo_etiquetas_val.get(etiqueta, 0)\n",
        "    print(f\"{etiqueta}: {conteo_train}, {conteo_val}, {conteo_test}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8yaF1KenQJ_5"
      },
      "outputs": [],
      "source": [
        "print(all_datasets_EVALution['train'].features['labels'].names)\n",
        "num_labels = all_datasets_EVALution['train'].features['labels'].num_classes\n",
        "print(f\"Number of labels: {num_labels}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(conteo_etiquetas_train.get('MadeOf', 0) + conteo_etiquetas_train.get('PartOf', 0))\n",
        "print(conteo_etiquetas_test.get('MadeOf', 0) + conteo_etiquetas_test.get('PartOf', 0))\n",
        "print(conteo_etiquetas_val.get('MadeOf', 0) + conteo_etiquetas_val.get('PartOf', 0))"
      ],
      "metadata": {
        "id": "n67XcUguf-Nn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wicymKLbPOef"
      },
      "source": [
        "## **Training the adapter**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inC0wazRQn2B"
      },
      "outputs": [],
      "source": [
        "config = RobertaConfig.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=num_labels,\n",
        ")\n",
        "model = RobertaModelWithHeads.from_pretrained(\n",
        "    model_name,\n",
        "    config=config,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qn0Qr7CdQ8AJ"
      },
      "outputs": [],
      "source": [
        "labels = all_datasets_EVALution['train']['labels']\n",
        "rel = all_datasets_EVALution['train']['rel']\n",
        "unique_pairs = set(zip(labels, rel))\n",
        "id2label = dict(unique_pairs)\n",
        "\n",
        "print(id2label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XiWLkSFxRoEp"
      },
      "outputs": [],
      "source": [
        "adapter_name = \"adapter-EVALution\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8ImqaV0RrZ_"
      },
      "outputs": [],
      "source": [
        "# Add a new adapter\n",
        "model.add_adapter(adapter_name)\n",
        "# Add a matching classification head\n",
        "model.add_classification_head(\n",
        "    adapter_name,\n",
        "    num_labels=num_labels,\n",
        "    id2label=id2label\n",
        "  )\n",
        "# Activate the adapter\n",
        "model.train_adapter(adapter_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mU7yv93cS8Cj"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "total_epochs = 10\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    learning_rate=1e-4,\n",
        "    num_train_epochs=total_epochs,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=2*batch_size,\n",
        "    logging_steps=200,\n",
        "    output_dir=\"./training_output\",\n",
        "    overwrite_output_dir=True,\n",
        "    # The next line is important to ensure the dataset labels are properly passed to the model\n",
        "    remove_unused_columns=False,\n",
        "    report_to='all',\n",
        "    load_best_model_at_end=True,     #load the best model at the end of training,\n",
        "    metric_for_best_model=metric_name,   #use metric_name for validation\n",
        "    evaluation_strategy='epoch',\n",
        "    save_strategy='epoch',\n",
        "    save_total_limit=1,\n",
        "    optim='adamw_torch'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MybG5M9tT5QP"
      },
      "outputs": [],
      "source": [
        "trainer = AdapterTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=encoded_datasets_EVALution['train'],\n",
        "    eval_dataset=encoded_datasets_EVALution['val'],\n",
        "    tokenizer=tokenizer, #it is needed the tokenizer that encoded the data for batching\n",
        "    compute_metrics=compute_metrics #to compute metric of the model in val dataset\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4VAmZH8T5Ss"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eiBdzu3oX3JK"
      },
      "outputs": [],
      "source": [
        "preds = trainer.predict(test_dataset=encoded_datasets_EVALution['test'])\n",
        "pred_labels = np.argmax(preds.predictions, axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PoipixicX3Zl"
      },
      "outputs": [],
      "source": [
        "real_rels = encoded_datasets_EVALution['test'].features['labels'].int2str(encoded_datasets_EVALution['test']['labels'])\n",
        "pred_rels = encoded_datasets_EVALution['test'].features['labels'].int2str(pred_labels)\n",
        "report = classification_report(real_rels, pred_rels, digits=3)\n",
        "report_dict = classification_report(real_rels, pred_rels, digits=3, output_dict=True)\n",
        "print(report)\n",
        "print(report_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BDtlYwB0Ka7V"
      },
      "outputs": [],
      "source": [
        "dataset = all_datasets_EVALution['test']\n",
        "file = 'results_iteration_4.txt'\n",
        "results_to_file(dataset, real_rels, pred_rels, file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tac0PjkFPObk"
      },
      "source": [
        "## **Fine-tunning the model**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JCSbjVKVEZZi"
      },
      "outputs": [],
      "source": [
        "model = RobertaForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PvMQeUQ6EJ-W"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "total_epochs = 10\n",
        "\n",
        "args = TrainingArguments(\n",
        "    learning_rate=2e-5,\n",
        "    num_train_epochs=total_epochs,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=2*batch_size,\n",
        "    logging_steps=200,\n",
        "    output_dir=\"./training_output\",\n",
        "    overwrite_output_dir=True,\n",
        "    # The next line is important to ensure the dataset labels are properly passed to the model\n",
        "    remove_unused_columns=False,\n",
        "    report_to='all',\n",
        "    load_best_model_at_end=True,     #load the best model at the end of training,\n",
        "    metric_for_best_model=metric_name,   #use metric_name for validation\n",
        "    evaluation_strategy='epoch',\n",
        "    save_strategy='epoch',\n",
        "    save_total_limit=1,\n",
        "    optim='adamw_torch'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7fsxRDOZGp_G"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model=model, #model to train\n",
        "    args=args,  #arguments to train\n",
        "    train_dataset=encoded_datasets_EVALution['train'],\n",
        "    eval_dataset=encoded_datasets_EVALution['val'],\n",
        "    tokenizer=tokenizer, #it is needed the tokenizer that encoded the data for batching\n",
        "    compute_metrics=compute_metrics #to compute metric of the model in val dataset\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mp6_qNlSG6tX"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l5nETjmGHG6T"
      },
      "outputs": [],
      "source": [
        "preds = trainer.predict(test_dataset=encoded_datasets_EVALution['test'])\n",
        "pred_labels = np.argmax(preds.predictions, axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23rIxkmnHH4k"
      },
      "outputs": [],
      "source": [
        "real_rels = encoded_datasets_EVALution['test'].features['labels'].int2str(encoded_datasets_EVALution['test']['labels'])\n",
        "pred_rels = encoded_datasets_EVALution['test'].features['labels'].int2str(pred_labels)\n",
        "report = classification_report(real_rels, pred_rels, digits=3)\n",
        "report_dict = classification_report(real_rels, pred_rels, digits=3, output_dict=True)\n",
        "print(report)\n",
        "print(report_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IaH7BcADHRMD"
      },
      "outputs": [],
      "source": [
        "dataset = all_datasets_EVALution['test']\n",
        "file = 'results_iteration_4.txt'\n",
        "results_to_file(dataset, real_rels, pred_rels, file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRKpEAwRqTh8"
      },
      "source": [
        "# **Adapters & Fine-Tuning training with ROOT09**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "reqXKGD1qdBe"
      },
      "outputs": [],
      "source": [
        "all_datasets_ROOT09, encoded_datasets_ROOT09 = load_data({'train':'lexical_datasets/ROOT09/train.tsv', 'val':'lexical_datasets/ROOT09/val.tsv', 'test':'lexical_datasets/ROOT09/test.tsv'})\n",
        "print(all_datasets_ROOT09)\n",
        "print(encoded_datasets_ROOT09)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yUEQDepYJUHd"
      },
      "outputs": [],
      "source": [
        "etiquetas_train = all_datasets_ROOT09[\"train\"][\"rel\"]\n",
        "etiquetas_test = all_datasets_ROOT09[\"test\"][\"rel\"]\n",
        "etiquetas_val = all_datasets_ROOT09[\"val\"][\"rel\"]\n",
        "\n",
        "conteo_etiquetas_train = Counter(etiquetas_train)\n",
        "conteo_etiquetas_test = Counter(etiquetas_test)\n",
        "conteo_etiquetas_val = Counter(etiquetas_val)\n",
        "\n",
        "etiquetas = set(etiquetas_train)\n",
        "\n",
        "for etiqueta in etiquetas:\n",
        "    conteo_train = conteo_etiquetas_train.get(etiqueta, 0)\n",
        "    conteo_test = conteo_etiquetas_test.get(etiqueta, 0)\n",
        "    conteo_val = conteo_etiquetas_val.get(etiqueta, 0)\n",
        "    print(f\"{etiqueta}: {conteo_train}, {conteo_val}, {conteo_test}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGhO8jk7s54j"
      },
      "outputs": [],
      "source": [
        "print(all_datasets_ROOT09['train'].features['labels'].names)\n",
        "num_labels = all_datasets_ROOT09['train'].features['labels'].num_classes\n",
        "print(f\"Number of labels: {num_labels}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iA53b_mrxR0I"
      },
      "source": [
        "## **Training the adapter**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IPIh9V9LqqAM"
      },
      "outputs": [],
      "source": [
        "config = RobertaConfig.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=num_labels,\n",
        ")\n",
        "model = RobertaModelWithHeads.from_pretrained(\n",
        "    model_name,\n",
        "    config=config,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95cxA-PGqqjq"
      },
      "outputs": [],
      "source": [
        "labels = all_datasets_ROOT09['train']['labels']\n",
        "rel = all_datasets_ROOT09['train']['rel']\n",
        "unique_pairs = set(zip(labels, rel))\n",
        "id2label = dict(unique_pairs)\n",
        "\n",
        "print(id2label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zs54U0qZquZk"
      },
      "outputs": [],
      "source": [
        "adapter_name = \"adapter-ROOT09\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oOGCxRS4q2Hk"
      },
      "outputs": [],
      "source": [
        "# Add a new adapter\n",
        "model.add_adapter(adapter_name)\n",
        "# Add a matching classification head\n",
        "model.add_classification_head(\n",
        "    adapter_name,\n",
        "    num_labels=num_labels,\n",
        "    id2label=id2label\n",
        "  )\n",
        "# Activate the adapter\n",
        "model.train_adapter(adapter_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0GXZ4RUoq58V"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "total_epochs = 10\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    learning_rate=1e-4,\n",
        "    num_train_epochs=total_epochs,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=2*batch_size,\n",
        "    logging_steps=200,\n",
        "    output_dir=\"./training_output\",\n",
        "    overwrite_output_dir=True,\n",
        "    # The next line is important to ensure the dataset labels are properly passed to the model\n",
        "    remove_unused_columns=False,\n",
        "    report_to='all',\n",
        "    load_best_model_at_end=True,     #load the best model at the end of training,\n",
        "    metric_for_best_model=metric_name,   #use metric_name for validation\n",
        "    evaluation_strategy='epoch',\n",
        "    save_strategy='epoch',\n",
        "    save_total_limit=1,\n",
        "    optim='adamw_torch'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvVxUeARq-l2"
      },
      "outputs": [],
      "source": [
        "trainer = AdapterTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=encoded_datasets_ROOT09['train'],\n",
        "    eval_dataset=encoded_datasets_ROOT09['val'],\n",
        "    tokenizer=tokenizer, #it is needed the tokenizer that encoded the data for batching\n",
        "    compute_metrics=compute_metrics #to compute metric of the model in val dataset\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3DpQQuXrPMd"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inRR8R99rQVX"
      },
      "outputs": [],
      "source": [
        "preds = trainer.predict(test_dataset=encoded_datasets_ROOT09['test'])\n",
        "pred_labels = np.argmax(preds.predictions, axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rxtB6pRMWaFM"
      },
      "outputs": [],
      "source": [
        "real_rels = encoded_datasets_ROOT09['test'].features['labels'].int2str(encoded_datasets_ROOT09['test']['labels'])\n",
        "pred_rels = encoded_datasets_ROOT09['test'].features['labels'].int2str(pred_labels)\n",
        "report = classification_report(real_rels, pred_rels, digits=3)\n",
        "report_dict = classification_report(real_rels, pred_rels, digits=3, output_dict=True)\n",
        "print(report)\n",
        "print(report_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_IQbQLWr6d9"
      },
      "outputs": [],
      "source": [
        "dataset = all_datasets_ROOT09['test']\n",
        "file = 'results_iteration_4.txt'\n",
        "results_to_file(dataset, real_rels, pred_rels, file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLsLeohPW1M-"
      },
      "source": [
        "## **Fine-tunning the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2GiWQtGdW5WP"
      },
      "outputs": [],
      "source": [
        "model = RobertaForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3w5YgkaW5ZF"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "total_epochs = 10\n",
        "\n",
        "args = TrainingArguments(\n",
        "    learning_rate=2e-5,\n",
        "    num_train_epochs=total_epochs,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=2*batch_size,\n",
        "    logging_steps=200,\n",
        "    output_dir=\"./training_output\",\n",
        "    overwrite_output_dir=True,\n",
        "    # The next line is important to ensure the dataset labels are properly passed to the model\n",
        "    remove_unused_columns=False,\n",
        "    report_to='all',\n",
        "    load_best_model_at_end=True,     #load the best model at the end of training,\n",
        "    metric_for_best_model=metric_name,   #use metric_name for validation\n",
        "    evaluation_strategy='epoch',\n",
        "    save_strategy='epoch',\n",
        "    save_total_limit=1,\n",
        "    optim='adamw_torch'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLHfxvmkXEFj"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model=model, #model to train\n",
        "    args=args,  #arguments to train\n",
        "    train_dataset=encoded_datasets_ROOT09['train'],\n",
        "    eval_dataset=encoded_datasets_ROOT09['val'],\n",
        "    tokenizer=tokenizer, #it is needed the tokenizer that encoded the data for batching\n",
        "    compute_metrics=compute_metrics #to compute metric of the model in val dataset\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8nQIj-_XXKhO"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cnAakGAiXb_v"
      },
      "outputs": [],
      "source": [
        "preds = trainer.predict(test_dataset=encoded_datasets_ROOT09['test'])\n",
        "pred_labels = np.argmax(preds.predictions, axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3Jri0-5XNbd"
      },
      "outputs": [],
      "source": [
        "real_rels = encoded_datasets_ROOT09['test'].features['labels'].int2str(encoded_datasets_ROOT09['test']['labels'])\n",
        "pred_rels = encoded_datasets_ROOT09['test'].features['labels'].int2str(pred_labels)\n",
        "report = classification_report(real_rels, pred_rels, digits=3)\n",
        "report_dict = classification_report(real_rels, pred_rels, digits=3, output_dict=True)\n",
        "print(report)\n",
        "print(report_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DfLC1RaeXjiH"
      },
      "outputs": [],
      "source": [
        "dataset = all_datasets_ROOT09['test']\n",
        "file = 'results_iteration_4.txt'\n",
        "results_to_file(dataset, real_rels, pred_rels, file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBZh42LvXoA5"
      },
      "source": [
        "# **Adapters & Fine-Tuning training with CogALex-V**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7QZhJuJNXs-2"
      },
      "outputs": [],
      "source": [
        "all_datasets_CogALexV, encoded_datasets_CogALexV = load_data({'train':'lexical_datasets/CogALexV/train.tsv', 'test':'lexical_datasets/CogALexV/test.tsv'})\n",
        "print(all_datasets_CogALexV)\n",
        "print(encoded_datasets_CogALexV)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wtoV1GsfNCuw"
      },
      "outputs": [],
      "source": [
        "etiquetas_train = all_datasets_CogALexV[\"train\"][\"rel\"]\n",
        "etiquetas_test = all_datasets_CogALexV[\"test\"][\"rel\"]\n",
        "\n",
        "conteo_etiquetas_train = Counter(etiquetas_train)\n",
        "conteo_etiquetas_test = Counter(etiquetas_test)\n",
        "\n",
        "etiquetas = set(etiquetas_train)\n",
        "\n",
        "for etiqueta in etiquetas:\n",
        "    conteo_train = conteo_etiquetas_train.get(etiqueta, 0)\n",
        "    conteo_test = conteo_etiquetas_test.get(etiqueta, 0)\n",
        "    print(f\"{etiqueta}: {conteo_train}, {conteo_test}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFcEWKznRtp2"
      },
      "outputs": [],
      "source": [
        "print(all_datasets_CogALexV['train'].features['labels'].names)\n",
        "num_labels = all_datasets_CogALexV['train'].features['labels'].num_classes\n",
        "print(f\"Number of labels: {num_labels}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIC9qwbHR6rk"
      },
      "source": [
        "## **Training the adapter**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9VtnrYqUR9g8"
      },
      "outputs": [],
      "source": [
        "config = RobertaConfig.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=num_labels,\n",
        ")\n",
        "model = RobertaModelWithHeads.from_pretrained(\n",
        "    model_name,\n",
        "    config=config,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zInS3eA4SBgh"
      },
      "outputs": [],
      "source": [
        "labels = all_datasets_CogALexV['train']['labels']\n",
        "rel = all_datasets_CogALexV['train']['rel']\n",
        "unique_pairs = set(zip(labels, rel))\n",
        "id2label = dict(unique_pairs)\n",
        "\n",
        "print(id2label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n_XnoZKWSJY1"
      },
      "outputs": [],
      "source": [
        "adapter_name = \"adapter-CogALexV\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yS21v6ulSUEX"
      },
      "outputs": [],
      "source": [
        "# Add a new adapter\n",
        "model.add_adapter(adapter_name)\n",
        "# Add a matching classification head\n",
        "model.add_classification_head(\n",
        "    adapter_name,\n",
        "    num_labels=num_labels,\n",
        "    id2label=id2label\n",
        "  )\n",
        "# Activate the adapter\n",
        "model.train_adapter(adapter_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYogZwvLSYLm"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "total_epochs = 10\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    learning_rate=1e-4,\n",
        "    num_train_epochs=total_epochs,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    logging_steps=200,\n",
        "    output_dir=\"./training_output\",\n",
        "    overwrite_output_dir=True,\n",
        "    # The next line is important to ensure the dataset labels are properly passed to the model\n",
        "    remove_unused_columns=False,\n",
        "    report_to='all',\n",
        "    save_strategy='epoch',\n",
        "    save_total_limit=1,\n",
        "    optim='adamw_torch'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GEyiOoUXSYre"
      },
      "outputs": [],
      "source": [
        "trainer = AdapterTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=encoded_datasets_CogALexV['train'],\n",
        "    tokenizer=tokenizer, #it is needed the tokenizer that encoded the data for batching\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9qYubpxOSss4"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7eEazrcCSuKC"
      },
      "outputs": [],
      "source": [
        "preds = trainer.predict(test_dataset=encoded_datasets_CogALexV['test'])\n",
        "pred_labels = np.argmax(preds.predictions, axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfhpZUk1Wxhx"
      },
      "outputs": [],
      "source": [
        "real_rels = encoded_datasets_CogALexV['test'].features['labels'].int2str(encoded_datasets_CogALexV['test']['labels'])\n",
        "pred_rels = encoded_datasets_CogALexV['test'].features['labels'].int2str(pred_labels)\n",
        "report = classification_report(real_rels, pred_rels, digits=3)\n",
        "report_dict = classification_report(real_rels, pred_rels, digits=3, output_dict=True)\n",
        "print(report)\n",
        "print(report_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XyMBlErsW-l-"
      },
      "outputs": [],
      "source": [
        "dataset = all_datasets_CogALexV['test']\n",
        "file = 'results_iteration_4.txt'\n",
        "results_to_file(dataset, real_rels, pred_rels, file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rByPgSX0cPm"
      },
      "source": [
        "## **Fine-tunning the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9AUTuAPc0e-9"
      },
      "outputs": [],
      "source": [
        "model = RobertaForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gOXrzT_40fyk"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "total_epochs = 10\n",
        "\n",
        "args = TrainingArguments(\n",
        "    learning_rate=2e-5,\n",
        "    num_train_epochs=total_epochs,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    logging_steps=100,\n",
        "    output_dir=\"./training_output\",\n",
        "    overwrite_output_dir=True,\n",
        "    # The next line is important to ensure the dataset labels are properly passed to the model\n",
        "    remove_unused_columns=False,\n",
        "    report_to='all',\n",
        "    save_strategy='epoch',\n",
        "    save_total_limit=1,\n",
        "    optim='adamw_torch'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fOdCSKCb0omw"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model=model, #model to train\n",
        "    args=args,  #arguments to train\n",
        "    train_dataset=encoded_datasets_CogALexV['train'],\n",
        "    tokenizer=tokenizer, #it is needed the tokenizer that encoded the data for batching\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VliAZ8l70o2F"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4YuXxH3L04FB"
      },
      "outputs": [],
      "source": [
        "preds = trainer.predict(test_dataset=encoded_datasets_CogALexV['test'])\n",
        "pred_labels = np.argmax(preds.predictions, axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZbqGRlWA04Sw"
      },
      "outputs": [],
      "source": [
        "real_rels = encoded_datasets_CogALexV['test'].features['labels'].int2str(encoded_datasets_CogALexV['test']['labels'])\n",
        "pred_rels = encoded_datasets_CogALexV['test'].features['labels'].int2str(pred_labels)\n",
        "report = classification_report(real_rels, pred_rels, digits=3)\n",
        "report_dict = classification_report(real_rels, pred_rels, digits=3, output_dict=True)\n",
        "print(report)\n",
        "print(report_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77T5-YJZ06Sl"
      },
      "outputs": [],
      "source": [
        "dataset = all_datasets_CogALexV['test']\n",
        "file = 'results_iteration_4.txt'\n",
        "results_to_file(dataset, real_rels, pred_rels, file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6aRaQfZj19e"
      },
      "source": [
        "# **Analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9z6eywMEpCYj"
      },
      "source": [
        "## **Extraction of misclassified relations in all iterations & Overlap errors between adapters and the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gg3wWh74pN7s"
      },
      "outputs": [],
      "source": [
        "# Función para procesar un archivo y encontrar las relaciones mal predichas\n",
        "def procesar_archivo(nombre_archivo):\n",
        "    relaciones_mal_predichas = []\n",
        "    with open(nombre_archivo, 'r') as file:\n",
        "        lines = file.readlines()[4:]  # Eliminar las primeras líneas\n",
        "\n",
        "        for line in lines:\n",
        "            line = line.strip()\n",
        "            words = line.split()\n",
        "\n",
        "            source = words[0]\n",
        "            target = words[1]\n",
        "            real_clas = words[2]\n",
        "            pred_clas = words[3]\n",
        "\n",
        "            if real_clas != pred_clas:\n",
        "                relaciones_mal_predichas.append((source, target, real_clas, pred_clas))\n",
        "\n",
        "    return relaciones_mal_predichas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R58c0Dy4rMGt"
      },
      "outputs": [],
      "source": [
        "def key_function(item):\n",
        "    return item[0].lower(), item[1].lower(), item[2], item[3]\n",
        "\n",
        "archivos = ['results_iteration_0.txt', 'results_iteration_1.txt', 'results_iteration_2.txt',\n",
        "         'results_iteration_3.txt', 'results_iteration_4.txt']\n",
        "output = 'misclassified_relations_rb_CogALexV_model.txt'\n",
        "relaciones_mal_predichas_por_archivo = []\n",
        "\n",
        "for archivo in archivos:\n",
        "    relaciones_mal_predichas = procesar_archivo(archivo)\n",
        "    relaciones_mal_predichas_por_archivo.append(relaciones_mal_predichas)\n",
        "\n",
        "for i, relaciones_mal_predichas in enumerate(relaciones_mal_predichas_por_archivo):\n",
        "    print(f\"Longitud de relaciones_mal_predichas_por_archivo[{i}]: {len(relaciones_mal_predichas)}\")\n",
        "\n",
        "relaciones_mal_predichas_comunes = set.intersection(*map(set, relaciones_mal_predichas_por_archivo))\n",
        "print(f\"Intersección de relaciones_mal_predichas_por_archivo: {len(relaciones_mal_predichas_comunes)}\")\n",
        "\n",
        "relaciones_mal_predichas_comunes = sorted(relaciones_mal_predichas_comunes, key=key_function)\n",
        "with open(output, \"w\") as file:\n",
        "    for relacion in relaciones_mal_predichas_comunes:\n",
        "        file.write(f\"{relacion[0]} {relacion[1]} {relacion[2]} {relacion[3]}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OyQFaL9VPIko"
      },
      "outputs": [],
      "source": [
        "# Función para procesar un archivo y encontrar las relaciones mal predichas\n",
        "def procesar_archivo(nombre_archivo):\n",
        "    relaciones_mal_predichas = []\n",
        "    with open(nombre_archivo, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "        for line in lines:\n",
        "            line = line.strip()\n",
        "            words = line.split()\n",
        "\n",
        "            source = words[0]\n",
        "            target = words[1]\n",
        "            real_clas = words[2]\n",
        "            pred_clas = words[3]\n",
        "\n",
        "            if real_clas != pred_clas:\n",
        "                relaciones_mal_predichas.append((source, target, real_clas, pred_clas))\n",
        "\n",
        "    return relaciones_mal_predichas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cu1cSKhELsTb"
      },
      "outputs": [],
      "source": [
        "def key_function(item):\n",
        "    return item[0].lower(), item[1].lower(), item[2], item[3]\n",
        "\n",
        "adapter = 'misclassified_relations_rb_CogALexV_adapters.txt'\n",
        "model = 'misclassified_relations_rb_CogALexV_model.txt'\n",
        "output = 'comparison_errors_rb_CogALexV.txt'\n",
        "\n",
        "relaciones_mal_predichas_adapter = procesar_archivo(adapter)\n",
        "relaciones_mal_predichas_model = procesar_archivo(model)\n",
        "\n",
        "print(f\"Longitud de relaciones_mal_predichas_adapter: {len(relaciones_mal_predichas_adapter)}\")\n",
        "print(f\"Longitud de relaciones_mal_predichas_model: {len(relaciones_mal_predichas_model)}\")\n",
        "\n",
        "set_adapter = set(relaciones_mal_predichas_adapter)\n",
        "set_model = set(relaciones_mal_predichas_model)\n",
        "\n",
        "interseccion = sorted(set_adapter.intersection(set_model), key=key_function)\n",
        "diferencia_adapter = sorted(set_adapter - set_model, key=key_function)\n",
        "diferencia_model = sorted(set_model - set_adapter, key=key_function)\n",
        "\n",
        "with open(output, \"w\") as file:\n",
        "    file.write(f\"Mal clasificadas en ambos casos: {len(interseccion)}\\n\\n\")\n",
        "    for relacion in interseccion:\n",
        "        file.write(f\"{relacion[0]} {relacion[1]} {relacion[2]} {relacion[3]}\\n\")\n",
        "\n",
        "    file.write(f\"\\nMal clasificadas con adapter y bien solo con modelo: {len(diferencia_adapter)}\\n\\n\")\n",
        "    for relacion in diferencia_adapter:\n",
        "        file.write(f\"{relacion[0]} {relacion[1]} {relacion[2]} {relacion[3]}\\n\")\n",
        "\n",
        "    file.write(f\"\\nMal clasificadas con solo modelo y bien con adapter: {len(diferencia_model)}\\n\\n\")\n",
        "    for relacion in diferencia_model:\n",
        "        file.write(f\"{relacion[0]} {relacion[1]} {relacion[2]} {relacion[3]}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Extraction of classified relations in all iterations**"
      ],
      "metadata": {
        "id": "3qnYotEvWPds"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para procesar un archivo y encontrar las relaciones bien predichas\n",
        "def procesar_archivo(nombre_archivo):\n",
        "    relaciones_bien_predichas = []\n",
        "    with open(nombre_archivo, 'r') as file:\n",
        "        lines = file.readlines()[4:]  # Eliminar las primeras líneas\n",
        "\n",
        "        for line in lines:\n",
        "            line = line.strip()\n",
        "            words = line.split()\n",
        "\n",
        "            source = words[0]\n",
        "            target = words[1]\n",
        "            real_clas = words[2]\n",
        "            pred_clas = words[3]\n",
        "\n",
        "            if real_clas == pred_clas:\n",
        "                relaciones_bien_predichas.append((source, target, real_clas, pred_clas))\n",
        "\n",
        "    return relaciones_bien_predichas"
      ],
      "metadata": {
        "id": "1t64ZzfGWR1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def key_function(item):\n",
        "    return item[0].lower(), item[1].lower(), item[2], item[3]\n",
        "\n",
        "archivos = ['results_iteration_0.txt', 'results_iteration_1.txt', 'results_iteration_2.txt',\n",
        "         'results_iteration_3.txt', 'results_iteration_4.txt']\n",
        "output = 'classified_relations_rl_EVALution_adapters.txt'\n",
        "relaciones_bien_predichas_por_archivo = []\n",
        "\n",
        "for archivo in archivos:\n",
        "    relaciones_bien_predichas = procesar_archivo(archivo)\n",
        "    relaciones_bien_predichas_por_archivo.append(relaciones_bien_predichas)\n",
        "\n",
        "for i, relaciones_bien_predichas in enumerate(relaciones_bien_predichas_por_archivo):\n",
        "    print(f\"Longitud de relaciones_bien_predichas_por_archivo[{i}]: {len(relaciones_bien_predichas)}\")\n",
        "\n",
        "relaciones_bien_predichas_comunes = set.intersection(*map(set, relaciones_bien_predichas_por_archivo))\n",
        "print(f\"Intersección de relaciones_bien_predichas_por_archivo: {len(relaciones_bien_predichas_comunes)}\")\n",
        "\n",
        "relaciones_bien_predichas_comunes = sorted(relaciones_bien_predichas_comunes, key=key_function)\n",
        "with open(output, \"w\") as file:\n",
        "    for relacion in relaciones_bien_predichas_comunes:\n",
        "        file.write(f\"{relacion[0]} {relacion[1]} {relacion[2]} {relacion[3]}\\n\")"
      ],
      "metadata": {
        "id": "wBcVgI_bWcAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_num_good_pred(nombre_archivo):\n",
        "    relaciones_acertadas = {}\n",
        "    num_pairs = 0\n",
        "\n",
        "    with open(nombre_archivo, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "        for line in lines:\n",
        "            line = line.strip()\n",
        "            words = line.split()\n",
        "\n",
        "            real_class = words[2]\n",
        "            pred_class = words[3]\n",
        "\n",
        "            if real_class != pred_class:\n",
        "               print(\"Wrong file!\")\n",
        "\n",
        "            if real_class in relaciones_acertadas:\n",
        "              relaciones_acertadas[real_class] += 1\n",
        "            else:\n",
        "              relaciones_acertadas[real_class] = 1\n",
        "\n",
        "            num_pairs = num_pairs + 1\n",
        "\n",
        "    return relaciones_acertadas, num_pairs"
      ],
      "metadata": {
        "id": "iQ8kOruKghak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "relaciones_acertadas, num_pairs = get_num_good_pred('classified_relations_rl_CogALexV_model.txt')\n",
        "print(relaciones_acertadas)\n",
        "print(f\"Total aciertos: {num_pairs}\")"
      ],
      "metadata": {
        "id": "CMOY20gIgxW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Confusion matrix for misclassified relations in all iterations with both adapters and the model**"
      ],
      "metadata": {
        "id": "TwF3mrehPQu4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_true_pred_labels(nombre_archivo):\n",
        "    true_labels = []\n",
        "    pred_labels = []\n",
        "    relaciones_falladas = {}\n",
        "\n",
        "    with open(nombre_archivo, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "        for line in lines:\n",
        "            line = line.strip()\n",
        "            words = line.split()\n",
        "\n",
        "            real_class = words[2]\n",
        "            pred_class = words[3]\n",
        "\n",
        "            true_labels.append(real_class)\n",
        "            pred_labels.append(pred_class)\n",
        "\n",
        "            if real_class in relaciones_falladas:\n",
        "              relaciones_falladas[real_class] += 1\n",
        "            else:\n",
        "              relaciones_falladas[real_class] = 1\n",
        "\n",
        "    return true_labels, pred_labels, relaciones_falladas"
      ],
      "metadata": {
        "id": "-LsDMSVPPU7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_true, y_pred, relaciones_falladas = get_true_pred_labels('comparison_errors_rl_EVALution.txt')\n",
        "print(relaciones_falladas)\n",
        "print(len(y_true), len(y_pred))"
      ],
      "metadata": {
        "id": "AzfLYV1wP_Ln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diccionario = {}\n",
        "for true, pred in zip(y_true, y_pred):\n",
        "  if true not in diccionario:\n",
        "    diccionario[true] = [(pred, 1)]\n",
        "  else:\n",
        "    indice = next((i for i, tupla in enumerate(diccionario[true]) if tupla[0] == pred), None)\n",
        "    if indice is None:\n",
        "      diccionario[true].append((pred, 1))\n",
        "    else:\n",
        "      tupla = diccionario[true][indice]\n",
        "      diccionario[true][indice] = (tupla[0], tupla[1] + 1)\n",
        "\n",
        "print(diccionario)"
      ],
      "metadata": {
        "id": "bucpPDHlhKen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "porcentajes_fallos_respecto_resto = {}\n",
        "for clave, valor in diccionario.items():\n",
        "  porcentajes_fallos_respecto_resto[clave] = [(rel, (num/relaciones_falladas[clave])*100) for (rel, num) in valor]\n",
        "\n",
        "print(porcentajes_fallos_respecto_resto)"
      ],
      "metadata": {
        "id": "mE1TYqt2lcNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "etiquetas = np.unique(y_true) if len(np.unique(y_true)) > len(np.unique(y_pred)) else np.unique(y_pred)\n",
        "print(etiquetas)"
      ],
      "metadata": {
        "id": "D7Hp1r2ESHfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, cmap='Blues', xticklabels=etiquetas, yticklabels=etiquetas)\n",
        "plt.xlabel('Predicciones')\n",
        "plt.ylabel('Valores reales')\n",
        "plt.title('Matriz de Confusión')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tvd6tlxVRQgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Average confusion matrix for misclassified relations**"
      ],
      "metadata": {
        "id": "Fh-u7oDOIviu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_labels(nombre_archivo):\n",
        "    true_labels = []\n",
        "    pred_labels = []\n",
        "\n",
        "    with open(nombre_archivo, 'r') as file:\n",
        "        lines = file.readlines()[4:]\n",
        "\n",
        "        for line in lines:\n",
        "            line = line.strip()\n",
        "            words = line.split()\n",
        "\n",
        "            real_class = words[2]\n",
        "            pred_class = words[3]\n",
        "\n",
        "            true_labels.append(real_class)\n",
        "            pred_labels.append(pred_class)\n",
        "\n",
        "    return true_labels, pred_labels"
      ],
      "metadata": {
        "id": "HyTSrCxXIxWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_true_0, y_pred_0 = get_labels('results_iteration_0.txt')\n",
        "y_true_1, y_pred_1 = get_labels('results_iteration_1.txt')\n",
        "y_true_2, y_pred_2 = get_labels('results_iteration_2.txt')\n",
        "y_true_3, y_pred_3 = get_labels('results_iteration_3.txt')\n",
        "y_true_4, y_pred_4 = get_labels('results_iteration_4.txt')"
      ],
      "metadata": {
        "id": "JgRfygbwJat_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "etiquetas = np.unique(y_true_0) if len(np.unique(y_true_0)) > len(np.unique(y_pred_0)) else np.unique(y_pred_0)\n",
        "print(etiquetas)"
      ],
      "metadata": {
        "id": "3qq4GMP1J4jy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "matriz_confusion_1 = confusion_matrix(y_true_0, y_pred_0)\n",
        "matriz_confusion_2 = confusion_matrix(y_true_1, y_pred_1)\n",
        "matriz_confusion_3 = confusion_matrix(y_true_2, y_pred_2)\n",
        "matriz_confusion_4 = confusion_matrix(y_true_3, y_pred_3)\n",
        "matriz_confusion_5 = confusion_matrix(y_true_4, y_pred_4)\n",
        "\n",
        "suma_matriz_confusion = matriz_confusion_1 + matriz_confusion_2 + matriz_confusion_3 + matriz_confusion_4 + matriz_confusion_5\n",
        "\n",
        "matriz_confusion_promedio = suma_matriz_confusion / 5\n",
        "\n",
        "np.fill_diagonal(matriz_confusion_promedio, 0)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(matriz_confusion_promedio, annot=True, cmap='Blues', xticklabels=etiquetas, yticklabels=etiquetas)\n",
        "plt.xlabel('Predicciones')\n",
        "plt.ylabel('Valores reales')\n",
        "plt.title('Matriz de Confusión Promedio')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "37-gZ-i9LzzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "suma_filas = matriz_confusion_promedio.sum(axis=1)\n",
        "matriz_confusion_porcentaje = (matriz_confusion_promedio / suma_filas[:, np.newaxis]) * 100\n",
        "\n",
        "print(matriz_confusion_porcentaje)"
      ],
      "metadata": {
        "id": "OAyg4lCAMlWL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Degree of overlap errors between adapters and the model**"
      ],
      "metadata": {
        "id": "Bn0YpMZUPCQD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_rels(nombre_archivo):\n",
        "    fallos = []\n",
        "\n",
        "    with open(nombre_archivo, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "        for line in lines:\n",
        "            line = line.strip()\n",
        "            words = line.split()\n",
        "\n",
        "            source = words[0]\n",
        "            target = words[1]\n",
        "            real_class = words[2]\n",
        "            pred_class = words[3]\n",
        "\n",
        "            fallos.append((source, target, real_class))\n",
        "\n",
        "    return fallos"
      ],
      "metadata": {
        "id": "QCgyFXtCPEZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fallos_adapter = get_rels('misclassified_relations_rl_CogALexV_adapters.txt')\n",
        "fallos_model = get_rels('misclassified_relations_rl_CogALexV_model.txt')"
      ],
      "metadata": {
        "id": "rFYImE-Pp6Px"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(fallos_adapter))\n",
        "print(len(set(fallos_adapter)))"
      ],
      "metadata": {
        "id": "IwCmlb8srpJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(fallos_model))\n",
        "print(len(set(fallos_model)))"
      ],
      "metadata": {
        "id": "cy0KQazQueEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fallos_adapter_set = set(fallos_adapter)\n",
        "fallos_model_set = set(fallos_model)\n",
        "\n",
        "interseccion = fallos_adapter_set.intersection(fallos_model_set)\n",
        "union = fallos_adapter_set.union(fallos_model_set)\n",
        "\n",
        "porcentaje_solape = (len(interseccion) / len(union)) * 100\n",
        "\n",
        "print(\"Porcentaje de solape:\", porcentaje_solape)"
      ],
      "metadata": {
        "id": "lg3VG5uEryE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(interseccion))\n",
        "print(len(union))"
      ],
      "metadata": {
        "id": "ygndtKdrtNM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAS000tZ6Ykh"
      },
      "source": [
        "# **Adapter layer combinations**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1LmwXx8tm_W"
      },
      "source": [
        "## **CogALexV**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oyZZO7hPtm_k"
      },
      "outputs": [],
      "source": [
        "all_datasets_CogALexV, encoded_datasets_CogALexV = load_data({'train':'lexical_datasets/CogALexV/train.tsv', 'test':'lexical_datasets/CogALexV/test.tsv'})\n",
        "print(all_datasets_CogALexV)\n",
        "print(encoded_datasets_CogALexV)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YUT4jcu3tm_v"
      },
      "outputs": [],
      "source": [
        "print(all_datasets_CogALexV['train'].features['labels'].names)\n",
        "num_labels = all_datasets_CogALexV['train'].features['labels'].num_classes\n",
        "print(f\"Number of labels: {num_labels}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kS9BFflCtm_5"
      },
      "outputs": [],
      "source": [
        "config = RobertaConfig.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=num_labels,\n",
        ")\n",
        "model = RobertaModelWithHeads.from_pretrained(\n",
        "    model_name,\n",
        "    config=config,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5l4ar3eWtm_9"
      },
      "outputs": [],
      "source": [
        "labels = all_datasets_CogALexV['train']['labels']\n",
        "rel = all_datasets_CogALexV['train']['rel']\n",
        "unique_pairs = set(zip(labels, rel))\n",
        "id2label = dict(unique_pairs)\n",
        "\n",
        "print(id2label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w5BLXI5mtnAA"
      },
      "outputs": [],
      "source": [
        "adapter_name = \"adapter-CogALexV\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "leave_out = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
        "print(leave_out)"
      ],
      "metadata": {
        "id": "GKCMJDjVt_vr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PfeifferConfig + leave_out\n",
        "adapter_config = AdapterConfig(\n",
        "    original_ln_before = True,\n",
        "    original_ln_after = True,\n",
        "    residual_before_ln = True,\n",
        "    adapter_residual_before_ln = False,\n",
        "    ln_before = False,\n",
        "    ln_after = False,\n",
        "    mh_adapter = False,\n",
        "    output_adapter = True,\n",
        "    non_linearity = \"relu\",\n",
        "    reduction_factor = 16,\n",
        "    leave_out = leave_out\n",
        ")"
      ],
      "metadata": {
        "id": "-RNnJQ3kt_g9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXIADQrUtnAB"
      },
      "outputs": [],
      "source": [
        "# Add a new adapter\n",
        "model.add_adapter(adapter_name, config=adapter_config)\n",
        "# Add a matching classification head\n",
        "model.add_classification_head(\n",
        "    adapter_name,\n",
        "    num_labels=num_labels,\n",
        "    id2label=id2label\n",
        "  )\n",
        "# Activate the adapter\n",
        "model.train_adapter(adapter_name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adapter_layers = model.get_adapter(adapter_name)\n",
        "print(adapter_layers)"
      ],
      "metadata": {
        "id": "qaCeHsS4uNor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8QFNZnf5tnAD"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "total_epochs = 10\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    learning_rate=1e-4,\n",
        "    num_train_epochs=total_epochs,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    logging_steps=200,\n",
        "    output_dir=\"./training_output\",\n",
        "    overwrite_output_dir=True,\n",
        "    # The next line is important to ensure the dataset labels are properly passed to the model\n",
        "    remove_unused_columns=False,\n",
        "    report_to='all',\n",
        "    save_strategy='epoch',\n",
        "    save_total_limit=1,\n",
        "    optim='adamw_torch'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SfLphAq4tnAF"
      },
      "outputs": [],
      "source": [
        "trainer = AdapterTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=encoded_datasets_CogALexV['train'],\n",
        "    tokenizer=tokenizer, #it is needed the tokenizer that encoded the data for batching\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YU-0tjLCtnAI"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fIVO7VwAtnAJ"
      },
      "outputs": [],
      "source": [
        "preds = trainer.predict(test_dataset=encoded_datasets_CogALexV['test'])\n",
        "pred_labels = np.argmax(preds.predictions, axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pRar5eX6tnAL"
      },
      "outputs": [],
      "source": [
        "real_rels = encoded_datasets_CogALexV['test'].features['labels'].int2str(encoded_datasets_CogALexV['test']['labels'])\n",
        "pred_rels = encoded_datasets_CogALexV['test'].features['labels'].int2str(pred_labels)\n",
        "report = classification_report(real_rels, pred_rels, digits=3)\n",
        "report_dict = classification_report(real_rels, pred_rels, digits=3, output_dict=True)\n",
        "print(report)\n",
        "print(report_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwezTtSKtnAM"
      },
      "outputs": [],
      "source": [
        "dataset = all_datasets_CogALexV['test']\n",
        "file = 'rl_CogALexV_16-23_4.txt'\n",
        "results_to_file(dataset, real_rels, pred_rels, file)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **EVALution**"
      ],
      "metadata": {
        "id": "7sR0XigRw5X9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XzDptd_-6pAo"
      },
      "outputs": [],
      "source": [
        "all_datasets_EVALution, encoded_datasets_EVALution = load_data({'train':'lexical_datasets/EVALution/train.tsv', 'val':'lexical_datasets/EVALution/val.tsv', 'test':'lexical_datasets/EVALution/test.tsv'})\n",
        "print(all_datasets_EVALution)\n",
        "print(encoded_datasets_EVALution)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "851gs1Em622e"
      },
      "outputs": [],
      "source": [
        "print(all_datasets_EVALution['train'].features['labels'].names)\n",
        "num_labels = all_datasets_EVALution['train'].features['labels'].num_classes\n",
        "print(f\"Number of labels: {num_labels}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1s5gS9c7LRX"
      },
      "outputs": [],
      "source": [
        "config = RobertaConfig.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=num_labels,\n",
        ")\n",
        "model = RobertaModelWithHeads.from_pretrained(\n",
        "    model_name,\n",
        "    config=config,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aGuRm49g7PAn"
      },
      "outputs": [],
      "source": [
        "labels = all_datasets_EVALution['train']['labels']\n",
        "rel = all_datasets_EVALution['train']['rel']\n",
        "unique_pairs = set(zip(labels, rel))\n",
        "id2label = dict(unique_pairs)\n",
        "\n",
        "print(id2label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O7ijIhqV7VY6"
      },
      "outputs": [],
      "source": [
        "adapter_name = \"adapter-EVALution\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ytOQe1Ib77ty"
      },
      "outputs": [],
      "source": [
        "leave_out = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
        "print(leave_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTNqF76YFpwm"
      },
      "outputs": [],
      "source": [
        "# PfeifferConfig + leave_out\n",
        "adapter_config = AdapterConfig(\n",
        "    original_ln_before = True,\n",
        "    original_ln_after = True,\n",
        "    residual_before_ln = True,\n",
        "    adapter_residual_before_ln = False,\n",
        "    ln_before = False,\n",
        "    ln_after = False,\n",
        "    mh_adapter = False,\n",
        "    output_adapter = True,\n",
        "    non_linearity = \"relu\",\n",
        "    reduction_factor = 16,\n",
        "    leave_out = leave_out\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8XAPfWp57VmT"
      },
      "outputs": [],
      "source": [
        "# Add a new adapter\n",
        "model.add_adapter(adapter_name, config=adapter_config)\n",
        "# Add a matching classification head\n",
        "model.add_classification_head(\n",
        "    adapter_name,\n",
        "    num_labels=num_labels,\n",
        "    id2label=id2label\n",
        "  )\n",
        "# Activate the adapter\n",
        "model.train_adapter(adapter_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3LgwADFL3lO"
      },
      "outputs": [],
      "source": [
        "adapter_layers = model.get_adapter(adapter_name)\n",
        "print(adapter_layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RkDyLIZ3MTD9"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "total_epochs = 10\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    learning_rate=1e-4,\n",
        "    num_train_epochs=total_epochs,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=2*batch_size,\n",
        "    logging_steps=200,\n",
        "    output_dir=\"./training_output\",\n",
        "    overwrite_output_dir=True,\n",
        "    # The next line is important to ensure the dataset labels are properly passed to the model\n",
        "    remove_unused_columns=False,\n",
        "    report_to='all',\n",
        "    load_best_model_at_end=True,     #load the best model at the end of training,\n",
        "    metric_for_best_model=metric_name,   #use metric_name for validation\n",
        "    evaluation_strategy='epoch',\n",
        "    save_strategy='epoch',\n",
        "    save_total_limit=1,\n",
        "    optim='adamw_torch'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x2VnSI-SMYy0"
      },
      "outputs": [],
      "source": [
        "trainer = AdapterTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=encoded_datasets_EVALution['train'],\n",
        "    eval_dataset=encoded_datasets_EVALution['val'],\n",
        "    tokenizer=tokenizer, #it is needed the tokenizer that encoded the data for batching\n",
        "    compute_metrics=compute_metrics #to compute metric of the model in val dataset\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63ewLpX6Meru"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8OyZUF2uPAtj"
      },
      "outputs": [],
      "source": [
        "preds = trainer.predict(test_dataset=encoded_datasets_EVALution['test'])\n",
        "pred_labels = np.argmax(preds.predictions, axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kOxZnD4kPBB0"
      },
      "outputs": [],
      "source": [
        "real_rels = encoded_datasets_EVALution['test'].features['labels'].int2str(encoded_datasets_EVALution['test']['labels'])\n",
        "pred_rels = encoded_datasets_EVALution['test'].features['labels'].int2str(pred_labels)\n",
        "report = classification_report(real_rels, pred_rels, digits=3)\n",
        "report_dict = classification_report(real_rels, pred_rels, digits=3, output_dict=True)\n",
        "print(report)\n",
        "print(report_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XPrtrMGt18Jg"
      },
      "outputs": [],
      "source": [
        "dataset = all_datasets_EVALution['test']\n",
        "file = 'rl_EVALution_16-23_4.txt'\n",
        "results_to_file(dataset, real_rels, pred_rels, file)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ROOT09**"
      ],
      "metadata": {
        "id": "_eXnZyaDxAcZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71ziitHuxLy8"
      },
      "outputs": [],
      "source": [
        "all_datasets_ROOT09, encoded_datasets_ROOT09 = load_data({'train':'lexical_datasets/ROOT09/train.tsv', 'val':'lexical_datasets/ROOT09/val.tsv', 'test':'lexical_datasets/ROOT09/test.tsv'})\n",
        "print(all_datasets_ROOT09)\n",
        "print(encoded_datasets_ROOT09)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0T6hWLqwxbcZ"
      },
      "outputs": [],
      "source": [
        "print(all_datasets_ROOT09['train'].features['labels'].names)\n",
        "num_labels = all_datasets_ROOT09['train'].features['labels'].num_classes\n",
        "print(f\"Number of labels: {num_labels}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = RobertaConfig.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=num_labels,\n",
        ")\n",
        "model = RobertaModelWithHeads.from_pretrained(\n",
        "    model_name,\n",
        "    config=config,\n",
        ")"
      ],
      "metadata": {
        "id": "ghVuG8uv3ptx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = all_datasets_ROOT09['train']['labels']\n",
        "rel = all_datasets_ROOT09['train']['rel']\n",
        "unique_pairs = set(zip(labels, rel))\n",
        "id2label = dict(unique_pairs)\n",
        "\n",
        "print(id2label)"
      ],
      "metadata": {
        "id": "oRd97aRy3xt1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adapter_name = \"adapter-ROOT09\""
      ],
      "metadata": {
        "id": "1gY86K5axEDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "leave_out = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
        "print(leave_out)"
      ],
      "metadata": {
        "id": "QVjwB6IDxnzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fmb3_xpGxyqv"
      },
      "outputs": [],
      "source": [
        "# PfeifferConfig + leave_out\n",
        "adapter_config = AdapterConfig(\n",
        "    original_ln_before = True,\n",
        "    original_ln_after = True,\n",
        "    residual_before_ln = True,\n",
        "    adapter_residual_before_ln = False,\n",
        "    ln_before = False,\n",
        "    ln_after = False,\n",
        "    mh_adapter = False,\n",
        "    output_adapter = True,\n",
        "    non_linearity = \"relu\",\n",
        "    reduction_factor = 16,\n",
        "    leave_out = leave_out\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZR-bwRzPx5WM"
      },
      "outputs": [],
      "source": [
        "# Add a new adapter\n",
        "model.add_adapter(adapter_name, config=adapter_config)\n",
        "# Add a matching classification head\n",
        "model.add_classification_head(\n",
        "    adapter_name,\n",
        "    num_labels=num_labels,\n",
        "    id2label=id2label\n",
        "  )\n",
        "# Activate the adapter\n",
        "model.train_adapter(adapter_name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adapter_layers = model.get_adapter(adapter_name)\n",
        "print(adapter_layers)"
      ],
      "metadata": {
        "id": "8FwaxT9SyBrN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "total_epochs = 10\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    learning_rate=1e-4,\n",
        "    num_train_epochs=total_epochs,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=2*batch_size,\n",
        "    logging_steps=200,\n",
        "    output_dir=\"./training_output\",\n",
        "    overwrite_output_dir=True,\n",
        "    # The next line is important to ensure the dataset labels are properly passed to the model\n",
        "    remove_unused_columns=False,\n",
        "    report_to='all',\n",
        "    load_best_model_at_end=True,     #load the best model at the end of training,\n",
        "    metric_for_best_model=metric_name,   #use metric_name for validation\n",
        "    evaluation_strategy='epoch',\n",
        "    save_strategy='epoch',\n",
        "    save_total_limit=1,\n",
        "    optim='adamw_torch'\n",
        ")"
      ],
      "metadata": {
        "id": "Zk-ORRS-yB4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = AdapterTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=encoded_datasets_ROOT09['train'],\n",
        "    eval_dataset=encoded_datasets_ROOT09['val'],\n",
        "    tokenizer=tokenizer, #it is needed the tokenizer that encoded the data for batching\n",
        "    compute_metrics=compute_metrics #to compute metric of the model in val dataset\n",
        ")"
      ],
      "metadata": {
        "id": "xPU1gZK5yFEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "i0rP3h-zyHeh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = trainer.predict(test_dataset=encoded_datasets_ROOT09['test'])\n",
        "pred_labels = np.argmax(preds.predictions, axis = 1)"
      ],
      "metadata": {
        "id": "j53X6dFhyIi0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real_rels = encoded_datasets_ROOT09['test'].features['labels'].int2str(encoded_datasets_ROOT09['test']['labels'])\n",
        "pred_rels = encoded_datasets_ROOT09['test'].features['labels'].int2str(pred_labels)\n",
        "report = classification_report(real_rels, pred_rels, digits=3)\n",
        "report_dict = classification_report(real_rels, pred_rels, digits=3, output_dict=True)\n",
        "print(report)\n",
        "print(report_dict)"
      ],
      "metadata": {
        "id": "DRxrIEx_yIlY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = all_datasets_ROOT09['test']\n",
        "file = 'rl_ROOT09_16-23_4.txt'\n",
        "results_to_file(dataset, real_rels, pred_rels, file)"
      ],
      "metadata": {
        "id": "DIMeycWUyWK-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "XDhnOvYDMZiu",
        "ArFuqFUlMr1N",
        "1YynnREkNCg3",
        "wicymKLbPOef",
        "Tac0PjkFPObk",
        "vRKpEAwRqTh8",
        "iA53b_mrxR0I",
        "zLsLeohPW1M-",
        "vBZh42LvXoA5",
        "eIC9qwbHR6rk",
        "6rByPgSX0cPm",
        "P6aRaQfZj19e",
        "9z6eywMEpCYj",
        "3qnYotEvWPds",
        "TwF3mrehPQu4",
        "Fh-u7oDOIviu",
        "Bn0YpMZUPCQD",
        "Z1LmwXx8tm_W",
        "7sR0XigRw5X9",
        "_eXnZyaDxAcZ"
      ],
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}